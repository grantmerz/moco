#!/bin/bash -l
#SBATCH --time=04:00:00
#SBATCH -C gpu

#SBATCH --account=m1759

#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-task=8
#SBATCH --cpus-per-task=80
#SBATCH -o sout/%j.out

#SBATCH --image=nersc/pytorch:ngc-20.08-v0
#SBATCH --volume="/dev/infiniband:/sys/class/infiniband_verbs"

time cp /global/cscratch1/sd/mustafa/SDSS/data_20200901/train.h5 /tmp
time cp /global/cscratch1/sd/mustafa/SDSS/data_20200901/valid.h5 /tmp

srun --nodes=1 --ntasks=1 shifter --env HDF5_USE_FILE_LOCKING=FALSE <<EOF
python -m torch.distributed.launch --nproc_per_node=8 train.py --amp --config=baseline
EOF
